import asyncio
import json
import os
from services.models_service import generate_summary

# æ¨¡æ‹Ÿæ—¥å¿—æ•°æ®
MOCK_LOGS = [
    "å®Œæˆäº† V2.0 è§„åˆ’æ–‡æ¡£çš„ç¼–å†™",
    "ä¿®å¤äº† API è¿æ¥ä¸ç¨³å®šçš„ Bug",
    "è°ƒç ”äº†æ™ºè°± AI çš„æ¥å…¥æ–¹æ¡ˆ",
    "ç”±äºç½‘ç»œåŸå› ï¼Œç”˜ç‰¹å›¾ç»„ä»¶çš„å®ç°æ¨è¿Ÿåˆ°ä¸‹å‘¨",
    "ç”¨æˆ·åé¦ˆæ³¨å†Œæµç¨‹ç¹çï¼Œéœ€è¦ä¼˜åŒ–"
]

async def test_prediction_logic():
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ™ºèƒ½é¢„æµ‹é€»è¾‘ (TDD - RED)...")
    
    # æ¨¡æ‹Ÿä»ç¯å¢ƒå˜é‡è·å– API é…ç½®
    api_key = os.getenv("GEMINI_API_KEY", "dummy_key")
    model_type = "gemini"
    model_name = "gemini-1.5-flash"
    
    # é¢„æµ‹åŠŸèƒ½åº”è¯¥æ˜¯ generate_summary çš„ä¸€éƒ¨åˆ†æˆ–è€…ç‹¬ç«‹å‡½æ•°
    # åœ¨æœ¬é˜¶æ®µï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨ generate_summary çš„è¿”å› JSON ä¸­å¢åŠ  nextWeekSuggestions å­—æ®µ
    
    log_content = "\n".join(MOCK_LOGS)
    
    print("ğŸ“¡ è°ƒç”¨ AI æœåŠ¡ç”Ÿæˆå‘¨æŠ¥å¹¶åŒ…å«å»ºè®®...")
    result_json_str = await generate_summary(api_key, model_type, model_name, log_content)
    
    if not result_json_str:
        print("âŒ å¤±è´¥: æœªè¿”å›ä»»ä½•å†…å®¹")
        return

    try:
        # å»æ‰ markdown ä»£ç å—åŒ…è£¹
        clean_json = result_json_str.replace("```json", "").replace("```", "").strip()
        result = json.loads(clean_json)
        
        print(f"ğŸ“Š ç”Ÿæˆçš„å‘¨æŠ¥æ‘˜è¦: {result.get('executiveSummary')[:50]}...")
        
        suggestions = result.get('nextWeekSuggestions')
        if suggestions and len(suggestions) > 0:
            print(f"âœ… æˆåŠŸæ‰¾åˆ° AI å»ºè®®: {suggestions}")
        else:
            print("âŒ å¤±è´¥: ç»“æœä¸­ç¼ºå¤± 'nextWeekSuggestions' å­—æ®µï¼ˆç¬¦åˆé¢„æœŸï¼Œç›®å‰å°šæœªå®ç°ï¼‰")
            
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        print(f"åŸå§‹è¾“å‡º: {result_json_str}")

if __name__ == "__main__":
    asyncio.run(test_prediction_logic())
