# 🚀 AI 功能集成最佳实践指南 (For Next Project) -- 简单版

如果您的下一个项目需要集成大模型 API（如 Gemini, OpenAI, Kimi 等），为了让我（AI 助手）最高效地为您开发，您可以参考以下结构向我下达指令。

这套方法论源自 `Log2weekly` 项目的成功经验。

---

## 📋 1. 高效指令通用模板

下次您启动新项目时，直接把填好这个表格发给我，我就能秒懂您的需求：

### 🎯 核心需求描述 (Example)
>
> "我需要一个 **[功能名称，如：智能周报生成器]**。它在后台运行，用户不需要跟 AI 聊天，只需要点击 **[触发按钮，如：生成周报]**，系统就把 **[输入数据，如：本周的 50 条日志]** 发给 AI，通过 AI 总结后，在界面上展示 **[输出形式，如：结构化的 Markdown 报告]**。"

### 🛠️ 关键技术决策点 (必填)

| 维度 | 给 AI 的指令选项 (二选一) | Log2weekly 的选择 (参考) |
| :--- | :--- | :--- |
| **交互模式** | A. **对话式** (像 ChatGPT 那样通过聊天框交互)<br>B. **后台式** (用户点按钮，AI 在后台处理数据，只看结果) | **B. 后台式** (更适合生产力工具) |
| **配置策略** | A. **系统内置 Key** (开发者付钱，用户免费用)<br>B. **用户自定义 Key** (用户填自己的 Key) | **B. 用户自定义** (成本低，隐私好) |
| **厂商选择** | A. **单模型** (只支持 GPT-4)<br>B. **多模型适配** (支持 Gemini + Kimi + OpenAI) | **B. 多模型** (Gemini 免费 + Kimi 中文强) |
| **验证机制** | A. **简单保存** (不做校验)<br>B. **强制验证** (保存前必须 Ping 通 API) | **B. 强制验证** (防止 Key 填错导致后续报错) |

---

## 💡 2. 您应该如何描述功能？(话术示例)

不要说：“帮我接入个 API。”
**请尝试这样说（复制即可用）：**

### 🟢 场景一：配置页设计
>
> "请帮我做一个 **AI 配置面板**。参考 Log2weekly 的经验，我需要支持 **[Gemini/Kimi]** 两种模型。
> **关键要求**：
>
> 1. 用户填完 Key 之后，必须点一个‘验证连接’的按钮。
> 2. 你要帮我写好后端的测试代码，如果 Key 是错的或者额度满了（429 错误），要清楚地告诉用户，不要只报个系统错误。
> 3. 验证通过后，自动把配置保存到数据库。"

### 🟢 场景二：业务逻辑处理
>
> "现在我们要实现 **[核心功能]** 了。
> 请帮我写一个 Prompt，把用户的 **[输入数据]** 转换成 **[目标格式]**。
> **注意**：
>
> 1. 数据量可能很大，需要考虑 token 限制吗？
> 2. 如果 API 超时了，前端要怎么提示？
> 3. 我希望输出是严格的 JSON 格式，方便我渲染到界面上。"

---

## ⚡️ 3. 为什么这样提需求最高效？

回顾 Log2weekly 的开发历程，我们做对了几件事，这也是您下次可以直接告诉我的：

1. **"不要硬编码"**：直接告诉我从一开始就做**多模型架构**（Model Agnostic），这样如果以后 Gemini 挂了，我们能马上切到 Kimi 或 DeepSeek，代码都不用大改。
2. **"自带验证"**：您刚才看到的 `test_kimi.py` 就是一个很好的例子。下次您直接说：“写功能前，先给我一个独立的测试脚本跑通 API。” 这样能排除 80% 的网络环境问题。
3. **"结构化输出"**：Log2weekly 的周报之所以能漂亮地展示，是因为我们强行要求 AI 输出 JSON 而不是一段纯文本。下次涉及数据展示时，请务必嘱咐我：“要求 AI 返回 JSON 格式。”

---

## 📝 总结

下次新项目开始时，您只需对我说：

> **"这是通过 API 集成 AI 的项目。请按 Log2weekly 的模式，先搭建支持多模型的配置中心，确保有 Key 有效性验证，然后我们再开发具体的业务功能。首选支持 Gemini 和 Kimi。"**

这句话包含了架构、交互、容错和选型的所有核心信息。
